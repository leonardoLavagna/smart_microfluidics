{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#notebooks.ensemble_models"
      ],
      "metadata": {
        "id": "DtSOPOEj0QrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "1m-Muw-JNVHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"smart_microfluidics\")"
      ],
      "metadata": {
        "id": "em3T6hGx0YvF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from sklearn.svm import SVR"
      ],
      "metadata": {
        "id": "2g8Er7W81xAN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "PlTNXnJKNWwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/cleaned_data.csv')\n",
        "df = df[df[\"OUTPUT\"] == 1]\n",
        "df = df.drop([\"OUTPUT\"], axis=1)\n",
        "df = df[df[\"CHIP\"] == \"Micromixer\"]\n",
        "df = df.drop([\"CHIP\"], axis=1)\n",
        "df = df[df[\"ML\"] == \"ESM\"]\n",
        "df = df.drop([\"ML\"], axis=1)\n",
        "df = df.drop(df.select_dtypes(include=['object', 'category']).columns, axis=1)"
      ],
      "metadata": {
        "id": "V9o9mgJt0f07"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=[\"SIZE\", \"PDI\"])\n",
        "y_size = df[\"SIZE\"]\n",
        "y_pdi = df[\"PDI\"]"
      ],
      "metadata": {
        "id": "Ry1MbkDO2Ba-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost for size predictions"
      ],
      "metadata": {
        "id": "ebJJEMyZNadQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_size, y_test_size = train_test_split(X, y_size, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'lambda': [0, 0.1, 1]\n",
        "}\n",
        "\n",
        "random_search_xgb = RandomizedSearchCV(xgb_model, param_distributions=param_grid_xgb, n_iter=50, scoring='neg_mean_squared_error', cv=5, random_state=42)\n",
        "random_search_xgb.fit(X_train_scaled, y_train_size)\n",
        "\n",
        "best_xgb_model = random_search_xgb.best_estimator_\n",
        "y_pred_xgb_size = best_xgb_model.predict(X_test_scaled)\n",
        "r2_xgb = r2_score(y_test_size, y_pred_xgb_size)\n",
        "mse_xgb = mean_squared_error(y_test_size, y_pred_xgb_size)\n",
        "mae_xgb = mean_absolute_error(y_test_size, y_pred_xgb_size)\n",
        "\n",
        "print(\"Optimized XGBoost Model for SIZE Evaluation:\")\n",
        "print(f\"Best Parameters: {random_search_xgb.best_params_}\")\n",
        "print(f\"R-squared: {r2_xgb}\")\n",
        "print(f\"Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"Mean Absolute Error: {mae_xgb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_1Kkolr1Moy",
        "outputId": "893e576d-307b-4a0e-9352-9e65d7aaf8df"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized XGBoost Model for SIZE Evaluation:\n",
            "Best Parameters: {'subsample': 0.7, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.2, 'lambda': 1, 'gamma': 0, 'colsample_bytree': 0.8}\n",
            "R-squared: 0.8289789823207528\n",
            "Mean Squared Error: 463.42585081807505\n",
            "Mean Absolute Error: 13.469367980957031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost for pdi predictions"
      ],
      "metadata": {
        "id": "7OPlYF-INtPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_pdi, y_test_pdi = train_test_split(X, y_pdi, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "xgb_model = XGBRegressor(random_state=42)\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'lambda': [0, 0.1, 1]\n",
        "}\n",
        "\n",
        "random_search_xgb = RandomizedSearchCV(xgb_model, param_distributions=param_grid_xgb, n_iter=50, scoring='neg_mean_squared_error', cv=5, random_state=42)\n",
        "random_search_xgb.fit(X_train_scaled, y_train_pdi)\n",
        "\n",
        "best_xgb_model = random_search_xgb.best_estimator_\n",
        "y_pred_xgb_pdi = best_xgb_model.predict(X_test_scaled)\n",
        "r2_xgb = r2_score(y_test_pdi, y_pred_xgb_pdi)\n",
        "mse_xgb = mean_squared_error(y_test_pdi, y_pred_xgb_pdi)\n",
        "mae_xgb = mean_absolute_error(y_test_pdi, y_pred_xgb_pdi)\n",
        "\n",
        "print(\"Optimized XGBoost Model for PDI Evaluation:\")\n",
        "print(f\"Best Parameters: {random_search_xgb.best_params_}\")\n",
        "print(f\"R-squared: {r2_xgb}\")\n",
        "print(f\"Mean Squared Error: {mse_xgb}\")\n",
        "print(f\"Mean Absolute Error: {mae_xgb}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtdOnsCt1m4_",
        "outputId": "d4e7270b-5fa6-4325-b500-07e49674e23b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized XGBoost Model for PDI Evaluation:\n",
            "Best Parameters: {'subsample': 1.0, 'n_estimators': 300, 'min_child_weight': 1, 'max_depth': 9, 'learning_rate': 0.01, 'lambda': 0.1, 'gamma': 0, 'colsample_bytree': 1.0}\n",
            "R-squared: 0.34588894116461155\n",
            "Mean Squared Error: 0.003431941253060487\n",
            "Mean Absolute Error: 0.03838176091086297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random forest regressor predictions for pdi"
      ],
      "metadata": {
        "id": "iJQOIOlOP32H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train_pdi, y_test_pdi = train_test_split(X, y_pdi, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300, 400, 500],\n",
        "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['sqrt', 'log2', None],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "random_search_rf = RandomizedSearchCV(rf_model, param_distributions=param_grid_rf,\n",
        "                                      n_iter=50, scoring='neg_mean_squared_error',\n",
        "                                      cv=5, random_state=42, n_jobs=-1)\n",
        "random_search_rf.fit(X_train_scaled, y_train_pdi)\n",
        "\n",
        "\n",
        "best_rf_model = random_search_rf.best_estimator_\n",
        "y_pred_rf_pdi = best_rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "r2_rf = r2_score(y_test_pdi, y_pred_rf_pdi)\n",
        "mse_rf = mean_squared_error(y_test_pdi, y_pred_rf_pdi)\n",
        "mae_rf = mean_absolute_error(y_test_pdi, y_pred_rf_pdi)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Optimized RandomForestRegressor Model for SIZE Evaluation:\")\n",
        "print(f\"Best Parameters: {random_search_rf.best_params_}\")\n",
        "print(f\"R-squared: {r2_rf}\")\n",
        "print(f\"Mean Squared Error: {mse_rf}\")\n",
        "print(f\"Mean Absolute Error: {mae_rf}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63VCsJMuP7Sd",
        "outputId": "ea6d60d2-e766-4660-b9da-e3b7b6f8f4d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized RandomForestRegressor Model for SIZE Evaluation:\n",
            "Best Parameters: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "R-squared: 0.5383643771732456\n",
            "Mean Squared Error: 0.0024220754510437216\n",
            "Mean Absolute Error: 0.03355048611111106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle_file_path = \"random_forest_model_for_pdi.pkl\"\n",
        "with open(pickle_file_path, \"wb\") as file:\n",
        "    pickle.dump(best_xgb_model, file)\n",
        "\n",
        "print(f\"Model saved to {pickle_file_path}\")"
      ],
      "metadata": {
        "id": "pcC_ILt4FEBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced PDI prediction"
      ],
      "metadata": {
        "id": "kgIwTPklISEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svr_model = SVR()\n",
        "gbr_model = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "meta_model_ridge = Ridge()\n",
        "\n",
        "stacking_model_pdi = StackingRegressor(\n",
        "    estimators=[('xgb', xgb_model), ('rf', rf_model), ('svr', svr_model), ('gbr', gbr_model)],\n",
        "    final_estimator=meta_model_ridge\n",
        ")\n",
        "\n",
        "stacking_model_pdi.fit(X_train_scaled, y_train_pdi)\n",
        "\n",
        "y_pred_pdi_stacked = stacking_model_pdi.predict(X_test_scaled)\n",
        "r2_pdi = r2_score(y_test_pdi, y_pred_pdi_stacked)\n",
        "mse_pdi = mean_squared_error(y_test_pdi, y_pred_pdi_stacked)\n",
        "mae_pdi = mean_absolute_error(y_test_pdi, y_pred_pdi_stacked)\n",
        "\n",
        "print(f\"Stacking Ensemble for PDI - R-squared: {r2_pdi}, MSE: {mse_pdi}, MAE: {mae_pdi}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjwxP69zG5k5",
        "outputId": "f98f85b7-5e27-4e25-ec94-f8e5a4c7ccda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Ensemble for PDI - R-squared: 0.5328156582541348, MSE: 0.0024511880567746787, MAE: 0.04254484741522172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensemble model"
      ],
      "metadata": {
        "id": "tf-ylYBpGEbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "size_model = best_xgb_model\n",
        "pdi_model = stacking_model_pdi\n",
        "\n",
        "# Use a simple linear regressor as the meta-model\n",
        "meta_model = LinearRegression()\n",
        "\n",
        "# Create separate stacking models for SIZE and PDI\n",
        "stacking_model_size = StackingRegressor(\n",
        "    estimators=[('size', size_model), ('pdi', pdi_model)],\n",
        "    final_estimator=meta_model\n",
        ")\n",
        "stacking_model_pdi = StackingRegressor(\n",
        "    estimators=[('size', size_model), ('pdi', pdi_model)],\n",
        "    final_estimator=meta_model\n",
        ")\n",
        "\n",
        "stacking_model_size.fit(X_train_scaled, y_train_size)\n",
        "stacking_model_pdi.fit(X_train_scaled, y_train_pdi)\n",
        "\n",
        "\n",
        "y_pred_size_stacked = stacking_model_size.predict(X_test_scaled)\n",
        "y_pred_pdi_stacked = stacking_model_pdi.predict(X_test_scaled)\n",
        "r2_size = r2_score(y_test_size, y_pred_size_stacked)\n",
        "mse_size = mean_squared_error(y_test_size, y_pred_size_stacked)\n",
        "mae_size = mean_absolute_error(y_test_size, y_pred_size_stacked)\n",
        "r2_pdi = r2_score(y_test_pdi, y_pred_pdi_stacked)\n",
        "mse_pdi = mean_squared_error(y_test_pdi, y_pred_pdi_stacked)\n",
        "mae_pdi = mean_absolute_error(y_test_pdi, y_pred_pdi_stacked)\n",
        "\n",
        "print(\"Stacking Ensemble Model Evaluation:\")\n",
        "print(f\"SIZE - R-squared: {r2_size}, MSE: {mse_size}, MAE: {mae_size}\")\n",
        "print(f\"PDI - R-squared: {r2_pdi}, MSE: {mse_pdi}, MAE: {mae_pdi}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy3xw2DTGGwc",
        "outputId": "260136e1-d9ab-443a-fa15-e196ea5932c4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Ensemble Model Evaluation:\n",
            "SIZE - R-squared: 0.874431019712665, MSE: 340.2617544655023, MAE: 11.834716059736861\n",
            "PDI - R-squared: 0.4725454271660092, MSE: 0.0027674094225640018, MAE: 0.03777433738473666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selected models"
      ],
      "metadata": {
        "id": "QPtzjtekM0Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"models/size_model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(stacking_model_size, file)\n",
        "\n",
        "print(\"Model saved to models/size_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zbfdrpJMvs5",
        "outputId": "0030c0a2-e7fd-461b-aaec-9916c4f09433"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to models/size_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"models/pdi_model.pkl\", \"wb\") as file:\n",
        "    pickle.dump(best_rf_model, file)\n",
        "\n",
        "print(\"Model saved to models/pdi_model.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuDIkDzgMzVZ",
        "outputId": "16836e85-f472-4813-8314-c1f9f040e223"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to models/pdi_model.pkl\n"
          ]
        }
      ]
    }
  ]
}